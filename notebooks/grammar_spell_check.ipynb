{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b7fb3bd",
   "metadata": {},
   "source": [
    "# BERT for grammar / spell check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "federal-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from transformers import BertTokenizer, BertForMaskedLM, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.nn import Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legitimate-sheet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "BERT_MODEL = 'bert-base-cased'  # using a cased tokenizer because case may matter in grammar / spelling\n",
    "\n",
    "# load up a tokenizer and BERT with MLM head\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)\n",
    "model = BertForMaskedLM.from_pretrained(BERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "muslim-limit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertOnlyMLMHead(\n",
       "  (predictions): BertLMPredictionHead(\n",
       "    (transform): BertPredictionHeadTransform(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (transform_act_fn): GELUActivation()\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note the decoder's output size is the size of the tokenizer's vocab. It is crucial to use a matching tokenizer\n",
    "model.cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "religious-eating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.vocab_size  # Looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee0cffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polished-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_predictions(phrase, top_n=1):\n",
    "    # add a pad token before and after the phrase. \n",
    "    #  I find this helps as BERT often will neglect the first and last token otherwise\n",
    "    phrase = f'{bert_tokenizer.pad_token} {phrase} {bert_tokenizer.pad_token}'\n",
    "    \n",
    "    input_ids = bert_tokenizer.encode(phrase, return_tensors=\"pt\")  # get the input_ids from the tokenizer\n",
    "    \n",
    "    outputs = model(input_ids)  # run the input ids against BERT\n",
    "    \n",
    "    # Get the nth most confident predicted tokens from the MLM head\n",
    "    prediction_scores = outputs.logits\n",
    "    predicted_tokens = prediction_scores.argsort()[:,:,-top_n].reshape(-1,)\n",
    "    \n",
    "    # Get the probability for each token\n",
    "    token_probas = Softmax(dim=2)(prediction_scores.sort().values)[:,:,-top_n].reshape(-1, )\n",
    "    \n",
    "    for proba, token in zip(token_probas, predicted_tokens):\n",
    "        print(f'Token: {bert_tokenizer.decode([token])} ({token})  Probability: {proba:.4f}')\n",
    "        \n",
    "    return predicted_tokens\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "physical-penetration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: . (119)  Probability: 0.0636\n",
      "Token: \" (107)  Probability: 0.9721\n",
      "Token: Last (4254)  Probability: 0.8593\n",
      "Token: time (1159)  Probability: 0.9999\n",
      "Token: I (146)  Probability: 0.9995\n",
      "Token: went (1355)  Probability: 0.4761\n",
      "Token: here (1303)  Probability: 0.9999\n",
      "Token: , (117)  Probability: 1.0000\n",
      "Token: my (1139)  Probability: 0.9564\n",
      "Token: bill (4550)  Probability: 0.9953\n",
      "Token: was (1108)  Probability: 0.9999\n",
      "Token: too (1315)  Probability: 1.0000\n",
      "Token: high (1344)  Probability: 0.9989\n",
      "Token: . (119)  Probability: 1.0000\n",
      "Token: \" (107)  Probability: 0.9807\n",
      "Token: . (119)  Probability: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 119,  107, 4254, 1159,  146, 1355, 1303,  117, 1139, 4550, 1108, 1315,\n",
       "        1344,  119,  107,  119])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_predictions('Last time I went here, me bill was too high.', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fuzzy-radio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: . (119)  Probability: 0.0563\n",
      "Token: \" (107)  Probability: 0.9262\n",
      "Token: My (1422)  Probability: 0.9989\n",
      "Token: wonderful (7310)  Probability: 0.9551\n",
      "Token: teacher (3218)  Probability: 0.9954\n",
      "Token: is (1110)  Probability: 0.9981\n",
      "Token: so (1177)  Probability: 0.9991\n",
      "Token: great (1632)  Probability: 0.9953\n",
      "Token: ! (106)  Probability: 1.0000\n",
      "Token: \" (107)  Probability: 0.9189\n",
      "Token: . (119)  Probability: 0.9683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 119,  107, 1422, 7310, 3218, 1110, 1177, 1632,  106,  107,  119])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_predictions('My wonderful teacher is so great!', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accepting-northern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: , (117)  Probability: 0.0202\n",
      "Token: ' (112)  Probability: 0.0596\n",
      "Token: my (1139)  Probability: 0.0006\n",
      "Token: brilliant (8431)  Probability: 0.0154\n",
      "Token: instructor (10332)  Probability: 0.0009\n",
      "Token: was (1108)  Probability: 0.0014\n",
      "Token: very (1304)  Probability: 0.0004\n",
      "Token: wonderful (7310)  Probability: 0.0027\n",
      "Token: . (119)  Probability: 0.0000\n",
      "Token: ' (112)  Probability: 0.0763\n",
      "Token: ! (106)  Probability: 0.0311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  117,   112,  1139,  8431, 10332,  1108,  1304,  7310,   119,   112,\n",
       "          106])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_predictions('My wonderful teacher is so great!', 2)  # 2nd choice  for wonderful is brilliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "annual-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: the (1103)  Probability: 0.0174\n",
      "Token: . (119)  Probability: 0.0066\n",
      "Token: The (1109)  Probability: 0.0002\n",
      "Token: great (1632)  Probability: 0.0093\n",
      "Token: Teacher (14208)  Probability: 0.0007\n",
      "Token: isn (2762)  Probability: 0.0001\n",
      "Token: such (1216)  Probability: 0.0002\n",
      "Token: brilliant (8431)  Probability: 0.0005\n",
      "Token: ? (136)  Probability: 0.0000\n",
      "Token: ! (106)  Probability: 0.0039\n",
      "Token: ? (136)  Probability: 0.0004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1103,   119,  1109,  1632, 14208,  2762,  1216,  8431,   136,   106,\n",
       "          136])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_predictions('My wonderful teacher is so great!', 3)  # 3rd choice  for wonderful is great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-stuart",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rough-organic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lookahead prediction\n",
    "\n",
    "def look_ahead(phrase):\n",
    "    # add a mask token at the end\n",
    "    phrase = f'{phrase} {bert_tokenizer.mask_token} {bert_tokenizer.pad_token}'\n",
    "    \n",
    "    input_ids = bert_tokenizer.encode(phrase, return_tensors=\"pt\")  # get the input_ids from the tokenizer\n",
    "    \n",
    "    outputs = model(input_ids)  # run the input ids against BERT\n",
    "    \n",
    "    # Get the nth most confident predicted tokens from the MLM head\n",
    "    prediction_scores = outputs.logits\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        print(f'Top Score {i}')\n",
    "        predicted_tokens = prediction_scores.argsort()[:,:,-i].reshape(-1,)\n",
    "\n",
    "        # Get the probability for each token\n",
    "        token_probas = Softmax(dim=2)(prediction_scores.sort().values)[:,:,-i].reshape(-1, )\n",
    "\n",
    "        for proba, token in list(zip(token_probas, predicted_tokens))[input_ids.shape[1] - 3:]:\n",
    "            print(f'Token: {bert_tokenizer.decode([token])} ({token})  Probability: {proba:.4f}')\n",
    "        print()\n",
    "    return predicted_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "strong-gazette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Score 1\n",
      "Token: time (1159)  Probability: 0.0528\n",
      "Token: ? (136)  Probability: 0.9924\n",
      "Token: . (119)  Probability: 0.9999\n",
      "\n",
      "Top Score 2\n",
      "Token: money (1948)  Probability: 0.0303\n",
      "Token: . (119)  Probability: 0.0056\n",
      "Token: ? (136)  Probability: 0.0001\n",
      "\n",
      "Top Score 3\n",
      "Token: numbers (2849)  Probability: 0.0271\n",
      "Token: ! (106)  Probability: 0.0015\n",
      "Token: ! (106)  Probability: 0.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1103,  117, 1284, 2866, 1412, 2849,  106,  106])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_ahead('Can we split the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "indirect-lobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Score 1\n",
      "Token: going (1280)  Probability: 0.8487\n",
      "Token: ? (136)  Probability: 0.9920\n",
      "Token: . (119)  Probability: 0.9986\n",
      "\n",
      "Top Score 2\n",
      "Token: now (1208)  Probability: 0.0605\n",
      "Token: . (119)  Probability: 0.0046\n",
      "Token: ? (136)  Probability: 0.0013\n",
      "\n",
      "Top Score 3\n",
      "Token: headed (2917)  Probability: 0.0298\n",
      "Token: ! (106)  Probability: 0.0032\n",
      "Token: ; (132)  Probability: 0.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 107,  117, 1231, 1128, 2917,  106,  132])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_ahead('Where are we')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "optical-investor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Score 1\n",
      "Token: unique (3527)  Probability: 0.0218\n",
      "Token: . (119)  Probability: 0.9514\n",
      "Token: . (119)  Probability: 0.9967\n",
      "\n",
      "Top Score 2\n",
      "Token: fun (4106)  Probability: 0.0216\n",
      "Token: ; (132)  Probability: 0.0225\n",
      "Token: ? (136)  Probability: 0.0010\n",
      "\n",
      "Top Score 3\n",
      "Token: special (1957)  Probability: 0.0206\n",
      "Token: ! (106)  Probability: 0.0186\n",
      "Token: ! (106)  Probability: 0.0008\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 107,  117, 4370, 1108, 1472, 4106, 1957,  106,  106])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_ahead('This class is kind of')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-cleaner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "excessive-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try fine-tuned model on Cola\n",
    "\n",
    "# https://nyu-mll.github.io/CoLA/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "posted-forward",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 8,551\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>label</th>\n",
       "      <th>label_notes</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>c_13</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Has Bill eaten his tuna?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>r-67</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joe is taller than Mary.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8099</th>\n",
       "      <td>ad03</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>The child wail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They can run.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>r-67</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tom says that it's going to rain but I don't b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5085</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It's mainly his attitude which convinced the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8062</th>\n",
       "      <td>ad03</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>He thought that Dracula was the Prince of Dark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>r-67</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did Merv show up and did you play chess?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4064</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John bothers me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>l-93</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They lent me a bicycle.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_source  label label_notes  \\\n",
       "5989            c_13      1         NaN   \n",
       "1558            r-67      1         NaN   \n",
       "8099            ad03      0           *   \n",
       "3536            ks08      1         NaN   \n",
       "1608            r-67      1         NaN   \n",
       "5085            ks08      1         NaN   \n",
       "8062            ad03      1         NaN   \n",
       "1315            r-67      1         NaN   \n",
       "4064            ks08      1         NaN   \n",
       "2719            l-93      1         NaN   \n",
       "\n",
       "                                               sentence  \n",
       "5989                           Has Bill eaten his tuna?  \n",
       "1558                           Joe is taller than Mary.  \n",
       "8099                                     The child wail  \n",
       "3536                                      They can run.  \n",
       "1608  Tom says that it's going to rain but I don't b...  \n",
       "5085  It's mainly his attitude which convinced the t...  \n",
       "8062  He thought that Dracula was the Prince of Dark...  \n",
       "1315           Did Merv show up and did you play chess?  \n",
       "4064                                   John bothers me.  \n",
       "2719                            They lent me a bicycle.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "cola_df = pd.read_csv(\"../data/cola.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(cola_df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "cola_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "through-commercial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba07d6c483b14ddba3c9430b1e2f2a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c3019db76f441dad1510ee60a1d5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f3ee3bf49e45299c80b75e9d6ca9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nlp import load_dataset, Dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "cola_dataset = Dataset.from_pandas(cola_df.sample(3000, random_state=42))\n",
    "\n",
    "# We will pad our dataset so that our input matrices are the same length and truncate anything longer than 512 tokens\n",
    "def preprocess_function(data):\n",
    "    return bert_tokenizer(data['sentence'], truncation=True)\n",
    "\n",
    "cola_dataset = cola_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Dataset has a built in train test split method\n",
    "cola_dataset = cola_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# DataCollatorWithPadding creates batch of data. It also dynamically pads text to the \n",
    "#  length of the longest element in the batch, making them all the same length. \n",
    "#  It's possible to pad your text in the tokenizer function with padding=True, dynamic padding is more efficient.\n",
    "data_collator = DataCollatorWithPadding(tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d6c209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bronze-examination",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "sequence_classification_model = BertForSequenceClassification.from_pretrained(\n",
    "    BERT_MODEL, num_labels=2,\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False # Whether the model returns all hidden-states.\n",
    ")\n",
    "sequence_classification_model.config.id2label = {0: 'INCORRECT', 1: 'CORRECT'}\n",
    "\n",
    "# freeze all but the last 2 encoder layers in BERT to speed up training\n",
    "for name, param in sequence_classification_model.bert.named_parameters():\n",
    "    if 'encoder.layer.10' in name:\n",
    "        break\n",
    "    param.requires_grad = False  # disable training in BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fixed-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./gs/results',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size * 2,\n",
    "    logging_dir='./gs/logs',\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=10,\n",
    "    logging_first_step=True,\n",
    "    evaluation_strategy='epoch',\n",
    "    eval_steps=1,\n",
    "    save_strategy='epoch'\n",
    ")\n",
    "\n",
    "# Define the trainer: \n",
    "\n",
    "trainer = Trainer(\n",
    "    model=sequence_classification_model,\n",
    "    args=training_args,\n",
    "    train_dataset=cola_dataset['train'],\n",
    "    eval_dataset=cola_dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mental-mailing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 600\n",
      "  Batch size = 64\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: label_notes, sentence, __index_level_0__, sentence_source. If label_notes, sentence, __index_level_0__, sentence_source are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 07:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6792384386062622,\n",
       " 'eval_accuracy': 0.6216666666666667,\n",
       " 'eval_runtime': 68.016,\n",
       " 'eval_samples_per_second': 8.821,\n",
       " 'eval_steps_per_second': 0.147}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get initial metrics\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "boolean-intranet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinanozdemir/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2400\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 150\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: label_notes, sentence, __index_level_0__, sentence_source. If label_notes, sentence, __index_level_0__, sentence_source are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 12:38, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.581500</td>\n",
       "      <td>0.576743</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.482200</td>\n",
       "      <td>0.577665</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 600\n",
      "  Batch size = 64\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: label_notes, sentence, __index_level_0__, sentence_source. If label_notes, sentence, __index_level_0__, sentence_source are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./gs/results/checkpoint-75\n",
      "Configuration saved in ./gs/results/checkpoint-75/config.json\n",
      "Model weights saved in ./gs/results/checkpoint-75/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 600\n",
      "  Batch size = 64\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: label_notes, sentence, __index_level_0__, sentence_source. If label_notes, sentence, __index_level_0__, sentence_source are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./gs/results/checkpoint-150\n",
      "Configuration saved in ./gs/results/checkpoint-150/config.json\n",
      "Model weights saved in ./gs/results/checkpoint-150/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=0.5357241650422414, metrics={'train_runtime': 761.5255, 'train_samples_per_second': 6.303, 'train_steps_per_second': 0.197, 'total_flos': 58048876588800.0, 'train_loss': 0.5357241650422414, 'epoch': 2.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adapted-torture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 600\n",
      "  Batch size = 64\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: label_notes, sentence, __index_level_0__, sentence_source. If label_notes, sentence, __index_level_0__, sentence_source are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5776650905609131,\n",
       " 'eval_accuracy': 0.74,\n",
       " 'eval_runtime': 68.3487,\n",
       " 'eval_samples_per_second': 8.779,\n",
       " 'eval_steps_per_second': 0.146,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get fine-tuned metrics\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b14c32b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./gs/results\n",
      "Configuration saved in ./gs/results/config.json\n",
      "Model weights saved in ./gs/results/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32bd97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5553f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bizarre-narrow",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./gs/results/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./gs/results\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"INCORRECT\",\n",
      "    \"1\": \"CORRECT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": null,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading configuration file ./gs/results/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./gs/results\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"INCORRECT\",\n",
      "    \"1\": \"CORRECT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": null,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./gs/results/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./gs/results.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /Users/sinanozdemir/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# make a classification pipeline\n",
    "pipe = pipeline(\"text-classification\", './gs/results', tokenizer=BERT_MODEL, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56948446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'INCORRECT', 'score': 0.8543031215667725}, {'label': 'CORRECT', 'score': 0.14569686353206635}]]\n",
      "[[{'label': 'INCORRECT', 'score': 0.36100929975509644}, {'label': 'CORRECT', 'score': 0.6389906406402588}]]\n",
      "[[{'label': 'INCORRECT', 'score': 0.0773123949766159}, {'label': 'CORRECT', 'score': 0.9226875901222229}]]\n"
     ]
    }
   ],
   "source": [
    "print(pipe('Me bar tab is to high.'))\n",
    "\n",
    "print(pipe('Me bar tab is too high.'))\n",
    "\n",
    "print(pipe('My bar tab is too high.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e86458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
