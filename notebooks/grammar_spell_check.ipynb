{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "federal-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from transformers import BertTokenizer, BertForMaskedLM, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.nn import Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legitimate-sheet",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "BERT_MODEL = 'bert-base-cased'  # using a cased tokenizer because case may matter in grammar / spelling\n",
    "\n",
    "# load up a tokenizer and BERT with MLM head\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)\n",
    "model = BertForMaskedLM.from_pretrained(BERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "muslim-limit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertOnlyMLMHead(\n",
       "  (predictions): BertLMPredictionHead(\n",
       "    (transform): BertPredictionHeadTransform(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note the decoder's output size is the size of the tokenizer's vocab. It is crucial to use a matching tokenizer\n",
    "model.cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "religious-eating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.vocab_size  # Looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polished-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_predictions(phrase, top_n=1):\n",
    "    # add a pad token before and after the phrase. \n",
    "    #  I find this helps as BERT often will neglect the first and last token otherwise\n",
    "    phrase = f'{bert_tokenizer.pad_token} {phrase} {bert_tokenizer.pad_token}'\n",
    "    \n",
    "    input_ids = bert_tokenizer.encode(phrase, return_tensors=\"pt\")  # get the input_ids from the tokenizer\n",
    "    \n",
    "    outputs = model(input_ids, labels=input_ids)  # run the input ids against BERT with the labels set as the input ids\n",
    "    \n",
    "    # Get the nth most confident predicted tokens from the MLM head\n",
    "    prediction_scores = outputs[1]\n",
    "    predicted_tokens = prediction_scores.argsort()[:,:,-top_n].reshape(-1,)\n",
    "    \n",
    "    # Get the probability for each token\n",
    "    token_probas = Softmax(dim=2)(prediction_scores.sort().values)[:,:,-top_n].reshape(-1, )\n",
    "    \n",
    "    for proba, token in zip(token_probas, predicted_tokens):\n",
    "        print(f'Token: {bert_tokenizer.decode([token])} ({token})  Probability: {proba:.4f}')\n",
    "        \n",
    "    return predicted_tokens\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "physical-penetration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: . (119)  Probability: 0.0636\n",
      "Token: \" (107)  Probability: 0.9721\n",
      "Token: Last (4254)  Probability: 0.8593\n",
      "Token: time (1159)  Probability: 0.9999\n",
      "Token: I (146)  Probability: 0.9995\n",
      "Token: went (1355)  Probability: 0.4761\n",
      "Token: here (1303)  Probability: 0.9999\n",
      "Token: , (117)  Probability: 1.0000\n",
      "Token: my (1139)  Probability: 0.9564\n",
      "Token: bill (4550)  Probability: 0.9953\n",
      "Token: was (1108)  Probability: 0.9999\n",
      "Token: too (1315)  Probability: 1.0000\n",
      "Token: high (1344)  Probability: 0.9989\n",
      "Token: . (119)  Probability: 1.0000\n",
      "Token: \" (107)  Probability: 0.9807\n",
      "Token: . (119)  Probability: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 119,  107, 4254, 1159,  146, 1355, 1303,  117, 1139, 4550, 1108, 1315,\n",
       "        1344,  119,  107,  119])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_predictions('Last time I went here, me bill was too high.', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fuzzy-radio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: . (119)  Probability: 0.0563\n",
      "Token: \" (107)  Probability: 0.9262\n",
      "Token: My (1422)  Probability: 0.9989\n",
      "Token: wonderful (7310)  Probability: 0.9551\n",
      "Token: teacher (3218)  Probability: 0.9954\n",
      "Token: is (1110)  Probability: 0.9981\n",
      "Token: so (1177)  Probability: 0.9991\n",
      "Token: great (1632)  Probability: 0.9953\n",
      "Token: ! (106)  Probability: 1.0000\n",
      "Token: \" (107)  Probability: 0.9189\n",
      "Token: . (119)  Probability: 0.9683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 119,  107, 1422, 7310, 3218, 1110, 1177, 1632,  106,  107,  119])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_predictions('My wonderful teacher is so great!', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accepting-northern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: , (117)  Probability: 0.0202\n",
      "Token: ' (112)  Probability: 0.0596\n",
      "Token: my (1139)  Probability: 0.0006\n",
      "Token: brilliant (8431)  Probability: 0.0154\n",
      "Token: instructor (10332)  Probability: 0.0009\n",
      "Token: was (1108)  Probability: 0.0014\n",
      "Token: very (1304)  Probability: 0.0004\n",
      "Token: wonderful (7310)  Probability: 0.0027\n",
      "Token: . (119)  Probability: 0.0000\n",
      "Token: ' (112)  Probability: 0.0763\n",
      "Token: ! (106)  Probability: 0.0311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  117,   112,  1139,  8431, 10332,  1108,  1304,  7310,   119,   112,\n",
       "          106])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_predictions('My wonderful teacher is so great!', 2)  # 2nd choice  for wonderful is brilliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "annual-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: the (1103)  Probability: 0.0174\n",
      "Token: . (119)  Probability: 0.0066\n",
      "Token: The (1109)  Probability: 0.0002\n",
      "Token: great (1632)  Probability: 0.0093\n",
      "Token: Teacher (14208)  Probability: 0.0007\n",
      "Token: isn (2762)  Probability: 0.0001\n",
      "Token: such (1216)  Probability: 0.0002\n",
      "Token: brilliant (8431)  Probability: 0.0005\n",
      "Token: ? (136)  Probability: 0.0000\n",
      "Token: ! (106)  Probability: 0.0039\n",
      "Token: ? (136)  Probability: 0.0004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1103,   119,  1109,  1632, 14208,  2762,  1216,  8431,   136,   106,\n",
       "          136])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_predictions('My wonderful teacher is so great!', 3)  # 3rd choice  for wonderful is great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-stuart",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rough-organic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lookahead prediction\n",
    "\n",
    "def look_ahead(phrase):\n",
    "    # add a mask token at the end\n",
    "    phrase = f'{phrase} {bert_tokenizer.mask_token} {bert_tokenizer.pad_token}'\n",
    "    \n",
    "    input_ids = bert_tokenizer.encode(phrase, return_tensors=\"pt\")  # get the input_ids from the tokenizer\n",
    "    \n",
    "    outputs = model(input_ids, labels=input_ids)  # run the input ids against BERT with the labels set as the input ids\n",
    "    \n",
    "    # Get the nth most confident predicted tokens from the MLM head\n",
    "    prediction_scores = outputs[1]\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        print(f'Top Score {i}')\n",
    "        predicted_tokens = prediction_scores.argsort()[:,:,-i].reshape(-1,)\n",
    "\n",
    "        # Get the probability for each token\n",
    "        token_probas = Softmax(dim=2)(prediction_scores.sort().values)[:,:,-i].reshape(-1, )\n",
    "\n",
    "        for proba, token in list(zip(token_probas, predicted_tokens))[input_ids.shape[1] - 3:]:\n",
    "            print(f'Token: {bert_tokenizer.decode([token])} ({token})  Probability: {proba:.4f}')\n",
    "        print()\n",
    "    return predicted_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "strong-gazette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Score 1\n",
      "Token: time (1159)  Probability: 0.0528\n",
      "Token: ? (136)  Probability: 0.9924\n",
      "Token: . (119)  Probability: 0.9999\n",
      "\n",
      "Top Score 2\n",
      "Token: money (1948)  Probability: 0.0303\n",
      "Token: . (119)  Probability: 0.0056\n",
      "Token: ? (136)  Probability: 0.0001\n",
      "\n",
      "Top Score 3\n",
      "Token: numbers (2849)  Probability: 0.0271\n",
      "Token: ! (106)  Probability: 0.0015\n",
      "Token: ! (106)  Probability: 0.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1103,  117, 1284, 2866, 1412, 2849,  106,  106])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_ahead('Can we split the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "indirect-lobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Score 1\n",
      "Token: going (1280)  Probability: 0.8487\n",
      "Token: ? (136)  Probability: 0.9920\n",
      "Token: . (119)  Probability: 0.9986\n",
      "\n",
      "Top Score 2\n",
      "Token: now (1208)  Probability: 0.0605\n",
      "Token: . (119)  Probability: 0.0046\n",
      "Token: ? (136)  Probability: 0.0013\n",
      "\n",
      "Top Score 3\n",
      "Token: headed (2917)  Probability: 0.0298\n",
      "Token: ! (106)  Probability: 0.0032\n",
      "Token: ; (132)  Probability: 0.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 107,  117, 1231, 1128, 2917,  106,  132])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_ahead('Where are we')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "optical-investor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Score 1\n",
      "Token: unique (3527)  Probability: 0.0218\n",
      "Token: . (119)  Probability: 0.9514\n",
      "Token: . (119)  Probability: 0.9967\n",
      "\n",
      "Top Score 2\n",
      "Token: fun (4106)  Probability: 0.0216\n",
      "Token: ; (132)  Probability: 0.0225\n",
      "Token: ? (136)  Probability: 0.0010\n",
      "\n",
      "Top Score 3\n",
      "Token: special (1957)  Probability: 0.0206\n",
      "Token: ! (106)  Probability: 0.0186\n",
      "Token: ! (106)  Probability: 0.0008\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 107,  117, 4370, 1108, 1472, 4106, 1957,  106,  106])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_ahead('This class is kind of')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-cleaner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "excessive-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try fine-tuned model on Cola\n",
    "\n",
    "# https://nyu-mll.github.io/CoLA/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "posted-forward",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 8,551\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>label</th>\n",
       "      <th>label_notes</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>bc01</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>He sees often Mary.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They read the interesting book.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8145</th>\n",
       "      <td>ad03</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Frantically at, Anson danced extremely Trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>r-67</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bob proved that this set is recursive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7549</th>\n",
       "      <td>sks13</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John likes himself.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>r-67</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My wife, somebody stole her handbag last night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neither of the cars has air conditioning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>c_13</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>She was kissed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>l-93</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The cook boned the fish.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>bc01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mickey looked up the reference.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_source  label label_notes  \\\n",
       "391             bc01      0           *   \n",
       "3544            ks08      1         NaN   \n",
       "8145            ad03      0           *   \n",
       "1235            r-67      1         NaN   \n",
       "7549           sks13      1         NaN   \n",
       "1834            r-67      1         NaN   \n",
       "4177            ks08      1         NaN   \n",
       "6122            c_13      1         NaN   \n",
       "2662            l-93      1         NaN   \n",
       "436             bc01      1         NaN   \n",
       "\n",
       "                                             sentence  \n",
       "391                               He sees often Mary.  \n",
       "3544                  They read the interesting book.  \n",
       "8145     Frantically at, Anson danced extremely Trade  \n",
       "1235           Bob proved that this set is recursive.  \n",
       "7549                              John likes himself.  \n",
       "1834  My wife, somebody stole her handbag last night.  \n",
       "4177        Neither of the cars has air conditioning.  \n",
       "6122                                  She was kissed.  \n",
       "2662                         The cook boned the fish.  \n",
       "436                   Mickey looked up the reference.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "cola_df = pd.read_csv(\"../data/cola.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(cola_df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "cola_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "through-commercial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e0d8267e3b45719e13901043f3689c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863a8302d46f42368e09e9771cf37e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e4a9c75a534cc5bdbe9d409dd8212c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1132c67a9394b0ea281ade777581f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nlp import load_dataset, Dataset\n",
    "\n",
    "\n",
    "cola_dataset = Dataset.from_pandas(cola_df.sample(5000, random_state=42))\n",
    "\n",
    "# Dataset has a built in train test split method\n",
    "cola_dataset = cola_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "train_set = cola_dataset['train']\n",
    "test_set = cola_dataset['test']\n",
    "\n",
    "# We will pad our dataset so that our input matrices are the same length and truncate anything longer than 512 tokens\n",
    "def preprocess(data):\n",
    "    return bert_tokenizer(data['sentence'], padding=True, truncation=True)\n",
    "\n",
    "train_set = train_set.map(preprocess, batched=True, batch_size=len(train_set))\n",
    "test_set = test_set.map(preprocess, batched=True, batch_size=len(test_set))\n",
    "\n",
    "train_set.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_set.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bronze-examination",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "sequence_classification_model = BertForSequenceClassification.from_pretrained(\n",
    "    BERT_MODEL, num_labels=2,\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# freeze all but the last 2 encoder layers in BERT to speed up training\n",
    "for param in list(sequence_classification_model.bert.parameters())[:165]:\n",
    "    param.requires_grad = False  # disable training in BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fixed-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "warmup_steps = 50\n",
    "weight_decay = 0.02\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./gs/results',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=warmup_steps,\n",
    "    weight_decay=weight_decay,\n",
    "    logging_dir='./gs/logs',\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=10,\n",
    "    logging_first_step=True\n",
    ")\n",
    "\n",
    "# Define the trainer: \n",
    "\n",
    "trainer = Trainer(\n",
    "    model=sequence_classification_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=test_set,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mental-mailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 08:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6666309237480164,\n",
       " 'eval_accuracy': 0.686,\n",
       " 'eval_runtime': 30.6732,\n",
       " 'eval_samples_per_second': 32.602,\n",
       " 'eval_steps_per_second': 1.043}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get initial metrics\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "boolean-intranet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 4000\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 06:58, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.676200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.597100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.565700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.652300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.593200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.618700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.608400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.595800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.566700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.516700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.553400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.545500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.473900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.512900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.472500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.529100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.520700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.476900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.485100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.490400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.450500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.554300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.492800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=0.5448903172016144, metrics={'train_runtime': 419.7677, 'train_samples_per_second': 19.058, 'train_steps_per_second': 0.596, 'total_flos': 193222181280000.0, 'train_loss': 0.5448903172016144, 'epoch': 2.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adapted-torture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4633745849132538,\n",
       " 'eval_accuracy': 0.796,\n",
       " 'eval_runtime': 32.4534,\n",
       " 'eval_samples_per_second': 30.813,\n",
       " 'eval_steps_per_second': 0.986,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get fine-tuned metrics\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "flying-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_grammatically_correct(text):\n",
    "    input_ids = bert_tokenizer.encode(text, return_tensors='pt')\n",
    "    return float(Softmax(dim=1)(sequence_classification_model(input_ids).logits)[0][1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "chinese-consultation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1595415621995926"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_grammatically_correct('Me bar tab is to high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "weighted-joint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3743801414966583"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_grammatically_correct('Me bar tab is too high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "coral-packing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7613747715950012"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_grammatically_correct('My bar tab is too high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-narrow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
