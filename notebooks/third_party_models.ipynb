{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "delayed-barcelona",
   "metadata": {},
   "source": [
    "### NER: Named Enitty Recognition: Using token classification to classify entites from natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "respective-milan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForTokenClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "revolutionary-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/savasy/bert-base-turkish-ner-cased\n",
    "\n",
    "custom_module = 'savasy/bert-base-turkish-ner-cased'\n",
    "\n",
    "turkish_ner_tokenizer = AutoTokenizer.from_pretrained(custom_module)\n",
    "turkish_ner_model = AutoModelForTokenClassification.from_pretrained(custom_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-monte",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pediatric-geology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.72424716,\n",
       "  'index': 5,\n",
       "  'word': 'Sinan',\n",
       "  'start': 20,\n",
       "  'end': 25},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.99879956,\n",
       "  'index': 7,\n",
       "  'word': 'San',\n",
       "  'start': 27,\n",
       "  'end': 30},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9977098,\n",
       "  'index': 8,\n",
       "  'word': 'Francisco',\n",
       "  'start': 31,\n",
       "  'end': 40}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"Merhaba! Benim adım Sinan. San Francisco'dan geliyorum\" # Hi! I'm Sinan. I come from San Francisco\"\n",
    "\n",
    "ner=pipeline('ner', model=turkish_ner_model, tokenizer=turkish_ner_tokenizer)\n",
    "ner(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-matthew",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "noble-danger",
   "metadata": {},
   "source": [
    "### Summarization: Using Bert 2 Bert to extract summaries from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "billion-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization\n",
    "\n",
    "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization')\n",
    "model = EncoderDecoderModel.from_pretrained('mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization').to(device)\n",
    "\n",
    "def generate_summary(text):\n",
    "    # cut off at BERT max length 512\n",
    "    inputs = tokenizer([text], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "\n",
    "    output = model.generate(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inclusive-worthy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 743\n",
      "The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\n",
      "\n",
      "\n",
      "\n",
      "Length of summary: 263\n",
      "the eiffel tower is 324 metres ( 1, 063 ft ) tall. its base is square, measuring 125 metres ( 410 ft ) on each side. it was the first structure to reach a height of 300 metres. it is the second tallest free - standing structure in france after the millau viaduct.\n"
     ]
    }
   ],
   "source": [
    "text = \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\"\n",
    "\n",
    "print(f'Length of text: {len(text)}')\n",
    "print(text)\n",
    "print('\\n\\n')\n",
    "\n",
    "summary = generate_summary(text)\n",
    "\n",
    "print(f'Length of summary: {len(summary)}')\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-replica",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "separated-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Alireza1044/albert-base-v2-qnli\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"Alireza1044/albert-base-v2-qnli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-square",
   "metadata": {},
   "source": [
    "### NLI: Natural Language Inference: the task of determining whether a “hypothesis” is true (called entailment), false (called contradiction), or undetermined (called neutral) given a “premise”.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "found-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/Alireza1044/albert-base-v2-qnli?text=I+like+you.+I+love+you\n",
    "from torch.nn import Softmax\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def nli(text):\n",
    "    inputs = tokenizer([text], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "\n",
    "    output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    return Softmax()(output.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "multiple-economy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-99c921dbff7c>:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return Softmax()(output.logits)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0270, 0.9730]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli('I like you. I love you.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "returning-convention",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-99c921dbff7c>:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return Softmax()(output.logits)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0195, 0.9805]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli('I like you. I hate you.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-hudson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-shell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "chronic-cloud",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset librispeech_asr (/Users/sinanozdemir/.cache/huggingface/datasets/librispeech_asr/clean/2.1.0/468ec03677f46a8714ac6b5b64dba02d246a228d92cbbad7f3dc190fa039eab1)\n",
      "Loading cached processed dataset at /Users/sinanozdemir/.cache/huggingface/datasets/librispeech_asr/clean/2.1.0/468ec03677f46a8714ac6b5b64dba02d246a228d92cbbad7f3dc190fa039eab1/cache-013ae9d5f1cf6018.arrow\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function.Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2Processor, HubertForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "model = HubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "    \n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "input_values = processor(ds[\"speech\"][0], return_tensors=\"pt\").input_values  # Batch size 1\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ethical-honor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A MAN SAID TO THE UNIVERSE SIR I EXIST'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-cloud",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "endangered-maple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WHAT A WONDERFUL CLASS'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa    \n",
    "local_file, sampling_rate = librosa.load('../data/sample.wav', sr=16000) # Downsample to 16kHz as the model was trained in\n",
    "\n",
    "input_values = processor(local_file, return_tensors=\"pt\", sampling_rate=sampling_rate).input_values\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-hopkins",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dependent-kuwait",
   "metadata": {},
   "source": [
    "<img title=\"a title\" alt=\"Speech Recognintion\" src=\"../images/speech_recognition.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-given",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
