{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "delayed-barcelona",
   "metadata": {},
   "source": [
    "### NER: Named Enitty Recognition: Using token classification to classify entites from natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "respective-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForTokenClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "revolutionary-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/savasy/bert-base-turkish-ner-cased\n",
    "\n",
    "custom_module = 'savasy/bert-base-turkish-ner-cased'\n",
    "\n",
    "turkish_ner_tokenizer = AutoTokenizer.from_pretrained(custom_module)\n",
    "turkish_ner_model = AutoModelForTokenClassification.from_pretrained(custom_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-monte",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pediatric-geology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.724247,\n",
       "  'index': 5,\n",
       "  'word': 'Sinan',\n",
       "  'start': 20,\n",
       "  'end': 25},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.99879956,\n",
       "  'index': 7,\n",
       "  'word': 'San',\n",
       "  'start': 27,\n",
       "  'end': 30},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.99771,\n",
       "  'index': 8,\n",
       "  'word': 'Francisco',\n",
       "  'start': 31,\n",
       "  'end': 40}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"Merhaba! Benim adım Sinan. San Francisco'dan geliyorum\" # Hi! I'm Sinan. I come from San Francisco\"\n",
    "\n",
    "ner=pipeline('ner', model=turkish_ner_model, tokenizer=turkish_ner_tokenizer)\n",
    "ner(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-matthew",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "noble-danger",
   "metadata": {},
   "source": [
    "### Summarization: Using Bert 2 Bert to extract summaries from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "billion-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization\n",
    "\n",
    "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization')\n",
    "model = EncoderDecoderModel.from_pretrained('mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization').to(device)\n",
    "\n",
    "def generate_summary(text):\n",
    "    # cut off at BERT max length 512\n",
    "    inputs = tokenizer([text], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "\n",
    "    output = model.generate(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inclusive-worthy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 743\n",
      "The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\n",
      "\n",
      "\n",
      "\n",
      "Length of summary: 263\n",
      "the eiffel tower is 324 metres ( 1, 063 ft ) tall. its base is square, measuring 125 metres ( 410 ft ) on each side. it was the first structure to reach a height of 300 metres. it is the second tallest free - standing structure in france after the millau viaduct.\n"
     ]
    }
   ],
   "source": [
    "text = \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\"\n",
    "\n",
    "print(f'Length of text: {len(text)}')\n",
    "print(text)\n",
    "print('\\n\\n')\n",
    "\n",
    "summary = generate_summary(text)\n",
    "\n",
    "print(f'Length of summary: {len(summary)}')\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-replica",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "separated-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "  \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Alireza1044/albert-base-v2-qnli\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"Alireza1044/albert-base-v2-qnli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-square",
   "metadata": {},
   "source": [
    "### NLI: Natural Language Inference: the task of determining whether a “hypothesis” is true (called entailment), false (called contradiction), or undetermined (called neutral) given a “premise”.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370e51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c429db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "found-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/Alireza1044/albert-base-v2-qnli?text=I+like+you.+I+love+you\n",
    "from torch.nn import Softmax\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def nli(text):\n",
    "    inputs = tokenizer([text], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "\n",
    "    output = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    return Softmax()(output.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "multiple-economy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y9/9xqbqkg90tnc0cmm0dxt985m0000gn/T/ipykernel_41961/2538707880.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return Softmax()(output.logits)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0270, 0.9730]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli('I like you. I love you.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "returning-convention",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y9/9xqbqkg90tnc0cmm0dxt985m0000gn/T/ipykernel_41961/2538707880.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return Softmax()(output.logits)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0195, 0.9805]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli('I like you. I hate you.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-hudson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badc28f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff684eb9",
   "metadata": {},
   "source": [
    "## MNLI - Multi-Genre Natural Language Inference can use classify using any set of potential classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91f1c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c092d00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'one day I will see the world',\n",
       " 'labels': ['travel', 'sightseeing', 'dancing', 'cooking'],\n",
       " 'scores': [0.8314740061759949,\n",
       "  0.16339346766471863,\n",
       "  0.0027388844173401594,\n",
       "  0.002393566071987152]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = \"one day I will see the world\"\n",
    "\n",
    "candidate_labels = ['travel', 'cooking', 'dancing', 'sightseeing']\n",
    "\n",
    "classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff6f46b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'one day I will see the world',\n",
       " 'labels': ['travel', 'sightseeing', 'dancing', 'cooking'],\n",
       " 'scores': [0.8314740061759949,\n",
       "  0.16339346766471863,\n",
       "  0.0027388844173401594,\n",
       "  0.002393566071987152]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(sequence_to_classify, candidate_labels, multi_label=False)  # Assuming there is only one right answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07a85f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'one day I will see the world',\n",
       " 'labels': ['travel', 'sightseeing', 'dancing', 'cooking'],\n",
       " 'scores': [0.994511067867279,\n",
       "  0.8578198552131653,\n",
       "  0.005706191528588533,\n",
       "  0.0018192835850641131]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(sequence_to_classify, candidate_labels, multi_label=True)  # There could be multple right answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee6f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-shell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chronic-cloud",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caa2545424d4321930517c188aee152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91537080daa64e9a9955f68089742f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset librispeech_asr_dummy/clean to /Users/sinanozdemir/.cache/huggingface/datasets/patrickvonplaten___librispeech_asr_dummy/clean/2.1.0/f2c70a4d03ab4410954901bde48c54b85ca1b7f9bf7d616e7e2a72b5ee6ddbfc...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53d919782504174b1e2717b3ed7ed9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76e47fb907d4e9b8f0c9502f7da47f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca9c478183d410ea35694fe6c698446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function map_to_array at 0x7f8bbffb1f70> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset librispeech_asr_dummy downloaded and prepared to /Users/sinanozdemir/.cache/huggingface/datasets/patrickvonplaten___librispeech_asr_dummy/clean/2.1.0/f2c70a4d03ab4410954901bde48c54b85ca1b7f9bf7d616e7e2a72b5ee6ddbfc. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8aee6a4b6bf44f7ae2a754388e63c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2Processor, HubertForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "model = HubertForCTC.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "    \n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "input_values = processor(ds[\"speech\"][0], return_tensors=\"pt\").input_values  # Batch size 1\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ethical-honor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A MAN SAID TO THE UNIVERSE SIR I EXIST'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-cloud",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "endangered-maple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WHAT A WONDERFUL CLASS'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa    \n",
    "local_file, sampling_rate = librosa.load('../data/sample.wav', sr=16000) # Downsample to 16kHz as the model was trained in\n",
    "\n",
    "input_values = processor(local_file, return_tensors=\"pt\", sampling_rate=sampling_rate).input_values\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-hopkins",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dependent-kuwait",
   "metadata": {},
   "source": [
    "<img title=\"a title\" alt=\"Speech Recognintion\" src=\"../images/speech_recognition.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-given",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb6417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
