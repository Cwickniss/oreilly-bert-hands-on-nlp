{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "involved-hartford",
   "metadata": {},
   "source": [
    "# Ingesting Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "classified-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from nlp import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "unsigned-region",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ingest tweets from the Kaggle disaster tweet comopetition\n",
    "\n",
    "tweets = pd.read_csv('../data/disaster.csv')\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "exclusive-onion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of tweet lengths. I don't love the left skewed data\n",
    "\n",
    "tweets['text'].apply(len).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "psychological-supervision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fitted-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tweets['id']\n",
    "del tweets['keyword']\n",
    "del tweets['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "renewable-canon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1\n",
       "1                Forest fire near La Ronge Sask. Canada       1\n",
       "2     All residents asked to 'shelter in place' are ...       1\n",
       "3     13,000 people receive #wildfires evacuation or...       1\n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1\n",
       "...                                                 ...     ...\n",
       "7608  Two giant cranes holding a bridge collapse int...       1\n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1\n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n",
       "7611  Police investigating after an e-bike collided ...       1\n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1\n",
       "\n",
       "[7613 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-brunswick",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "blank-county",
   "metadata": {},
   "source": [
    "# Preprocessing Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "after-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "URL_REGEX = re.compile('http(s)?:\\/\\/t.co\\/\\w+')\n",
    "MENTION_REGEX = re.compile('@\\w+')\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    # remove mentions, the pound sign, and replace urls with URL token\n",
    "    tweet = re.sub(URL_REGEX, 'url', tweet)  # replace urls with url. Assumes that the mention of a url is significant\n",
    "    tweet = re.sub(MENTION_REGEX, '', tweet)  # remove mentions entirely\n",
    "    tweet = tweet.replace('#', '')  # remove pound signs\n",
    "    \n",
    "    return tweet.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "numerous-plaza",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MEG issues Hazardous Weather Outlook (HWO) url'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweet('@prof_oz MEG issues Hazardous #Weather Outlook (HWO) http://t.co/3X6RBQJHn3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-record",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dietary-glasgow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive wildfires evacuation ord...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>The out of control wild fires in California ev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. url</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0     Our Deeds are the Reason of this earthquake Ma...       1\n",
       "1                Forest fire near La Ronge Sask. Canada       1\n",
       "2     All residents asked to 'shelter in place' are ...       1\n",
       "3     13,000 people receive wildfires evacuation ord...       1\n",
       "4     Just got sent this photo from Ruby Alaska as s...       1\n",
       "...                                                 ...     ...\n",
       "7608  Two giant cranes holding a bridge collapse int...       1\n",
       "7609  The out of control wild fires in California ev...       1\n",
       "7610     M1.94 [01:04 UTC]?5km S of Volcano Hawaii. url       1\n",
       "7611  Police investigating after an e-bike collided ...       1\n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1\n",
       "\n",
       "[7613 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['text'] = tweets['text'].apply(clean_tweet)\n",
    "\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8961ed88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets['target'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7178d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "rental-allowance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWhklEQVR4nO3df5Dc9WHe8fdTKZYFF5CI4qssaXpKRnEqUJtYF0rjOr2z3KLYFDFtycgDsajJaOohDknl2lI9U0//0IQkxUlcjDsaRC1XNldFIUGFKjFRuDKZQagIG0sCK8iRKktgya6BcISRferTP/bLeHvscXe7e7df+DyvmZv77ufz/fHc6fbZ3e/+kGwTERHl+Fu9DhAREXMrxR8RUZgUf0REYVL8ERGFSfFHRBRmfq8DTGXJkiUeGBhoOffKK69w6aWXzm2gGUi+9tU5GyRfp+qcr87ZYPr5Dh8+/F3bP95y0natv9auXevJPPLII5PO1UHyta/O2ezk61Sd89U5mz39fMATnqRXpzzVI+leSeclHW0x93FJlrSkaWybpBOSjku6tml8raQj1dxnJWnKm6yIiOi66Zzj/wKwfuKgpBXAPwFON42tBjYCV1bb3C1pXjX9eWAzsKr6et0+IyJi9k1Z/LYfBb7XYup3gU8AzW/93QCM2L5g+yRwArha0lLgMtuPVQ9Bvgjc0Gn4iIiYubae3JV0PXDW9lMTztgsAw42XT5Tjf2gWp44Ptn+N9N4dEB/fz+jo6Mt1xsbG5t0rg6Sr311zgbJ16k656tzNuhSvslO/jd/AQPA0Wr5EuBx4PLq8ilgSbX8OeDmpu12Av8C+Dngz5rG3wv89+kcO0/uzp4656tzNjv5OlXnfHXOZnfnyd127vH/JLASeO3e/nLgSUlX07gnv6Jp3eXAc9X48hbjERExx2b8Bi7bR2y/w/aA7QEapf5u298G9gEbJS2QtJLGk7iHbD8PvCzpmurVPB8GHujejxEREdM1nZdz3gc8BrxL0hlJt062ru1jwB7gaeBPgNtsX6ymPwrcQ+MJ328C+zvMHhERbZjyVI/tD00xPzDh8nZge4v1ngCummG+iIjostp/ZENE1MfA1oe6sp8ta8a5ZQb7OnXHB7ty3GjIh7RFRBQmxR8RUZgUf0REYVL8ERGFSfFHRBQmxR8RUZgUf0REYVL8ERGFSfFHRBQmxR8RUZgUf0REYVL8ERGFSfFHRBQmxR8RUZgUf0REYVL8ERGFSfFHRBQmxR8RUZgUf0REYVL8ERGFmbL4Jd0r6byko01jvyPpG5K+LumPJC1qmtsm6YSk45KubRpfK+lINfdZSer6TxMREVOazj3+LwDrJ4w9DFxl++8BfwlsA5C0GtgIXFltc7ekedU2nwc2A6uqr4n7jIiIOTBl8dt+FPjehLGv2B6vLh4EllfLG4AR2xdsnwROAFdLWgpcZvsx2wa+CNzQpZ8hIiJmoBvn+D8C7K+WlwHfapo7U40tq5YnjkdExBxT4w74FCtJA8CDtq+aMP4pYBD457Yt6XPAY7Z3V/M7gf8BnAZ+0/b7q/H3Ap+w/c8mOd5mGqeF6O/vXzsyMtIy19jYGH19fdP5OXsi+dpX52xQbr4jZ1/qyn76F8K5V6e//ppll3fluNPxVvm3HR4ePmx7sNXc/HYPLmkTcB2wzj+89TgDrGhabTnwXDW+vMV4S7Z3ADsABgcHPTQ01HK90dFRJpurg+RrX52zQbn5btn6UFf2s2XNOHcemX79nLppqCvHnY4S/m3bKn5J64FPAv/Y9t80Te0DvizpM8A7aTyJe8j2RUkvS7oGeBz4MPCfOkoeURnoUhnNxJY14wzN+VEjumPK4pd0HzAELJF0Bvg0jVfxLAAerl6VedD2v7Z9TNIe4GlgHLjN9sVqVx+l8QqhhTSeE9hPRETMuSmL3/aHWgzvfIP1twPbW4w/AVz1+i0iImIu5Z27ERGFSfFHRBQmxR8RUZgUf0REYVL8ERGFafsNXBHRO1O9d2HLmvGuvdkq3npyjz8iojAp/oiIwqT4IyIKk+KPiChMij8iojAp/oiIwqT4IyIKk9fxR7SpF/8PQEQ35B5/RERhUvwREYVJ8UdEFCbFHxFRmBR/RERhUvwREYVJ8UdEFCbFHxFRmCmLX9K9ks5LOto0doWkhyU9W31f3DS3TdIJScclXds0vlbSkWrus5LU/R8nIiKmMp17/F8A1k8Y2wocsL0KOFBdRtJqYCNwZbXN3ZLmVdt8HtgMrKq+Ju4zIiLmwJTFb/tR4HsThjcAu6rlXcANTeMjti/YPgmcAK6WtBS4zPZjtg18sWmbiIiYQ2r08BQrSQPAg7avqi6/aHtR0/wLthdLugs4aHt3Nb4T2A+cAu6w/f5q/L3AJ21fN8nxNtN4dEB/f//akZGRlrnGxsbo6+ub3k/aA8nXvplkO3L2pVlO83r9C+Hcq3N+2Gl7q+Vbs+zy2QszQZ2vFzD9fMPDw4dtD7aa6/aHtLU6b+83GG/J9g5gB8Dg4KCHhoZarjc6Ospkc3VQUr5uf2DZljUXufMvXpnm2nP/WYNb1oxz55H6fsbhWy3fqZuGZi/MBCVcb9t9Vc+56vQN1ffz1fgZYEXTesuB56rx5S3GIyJijrVb/PuATdXyJuCBpvGNkhZIWknjSdxDtp8HXpZ0TfVqng83bRMREXNoysdaku4DhoAlks4AnwbuAPZIuhU4DdwIYPuYpD3A08A4cJvti9WuPkrjFUILaZz339/VnyQiIqZlyuK3/aFJptZNsv52YHuL8SeAq2aULiIiui7v3I2IKEyKPyKiMCn+iIjCpPgjIgqT4o+IKEyKPyKiMCn+iIjCpPgjIgqT4o+IKEyKPyKiMCn+iIjCpPgjIgqT4o+IKEyKPyKiMCn+iIjCpPgjIgqT4o+IKEyKPyKiMCn+iIjCpPgjIgqT4o+IKExHxS/pNyQdk3RU0n2S3i7pCkkPS3q2+r64af1tkk5IOi7p2s7jR0TETLVd/JKWAb8GDNq+CpgHbAS2AgdsrwIOVJeRtLqavxJYD9wtaV5n8SMiYqY6PdUzH1goaT5wCfAcsAHYVc3vAm6oljcAI7Yv2D4JnACu7vD4ERExQ7Ld/sbS7cB24FXgK7ZvkvSi7UVN67xge7Gku4CDtndX4zuB/bb3ttjvZmAzQH9//9qRkZGWxx8bG6Ovr6/t/LOtpHxHzr7Ulf28pn8hnHu1q7vsquTrzEzzrVl2+eyFmeCtcr0dHh4+bHuw1dz8dg9enbvfAKwEXgT+QNLNb7RJi7GWtzq2dwA7AAYHBz00NNRyh6Ojo0w2Vwcl5btl60Nd2c9rtqwZ584jbf95zrrk68xM8526aWj2wkxQwvW2k1M97wdO2v6O7R8A9wM/D5yTtBSg+n6+Wv8MsKJp++U0Tg1FRMQc6qT4TwPXSLpEkoB1wDPAPmBTtc4m4IFqeR+wUdICSSuBVcChDo4fERFtaPuxoO3HJe0FngTGga/SOD3TB+yRdCuNG4cbq/WPSdoDPF2tf5vtix3mj4iIGeroJKDtTwOfnjB8gca9/1brb6fxZHBERPRI3rkbEVGYFH9ERGFS/BERhUnxR0QUJsUfEVGYFH9ERGFS/BERhUnxR0QUJsUfEVGYFH9ERGFS/BERhUnxR0QUJsUfEVGYFH9ERGFS/BERhUnxR0QUJsUfEVGYFH9ERGFS/BERhUnxR0QUJsUfEVGYFH9ERGHmd7KxpEXAPcBVgIGPAMeB/wYMAKeAX7L9QrX+NuBW4CLwa7b/tJPjx+sNbH1o2utuWTPOLTNYPyLeGjq9x//7wJ/Y/mng7wPPAFuBA7ZXAQeqy0haDWwErgTWA3dLmtfh8SMiYobaLn5JlwG/AOwEsP192y8CG4Bd1Wq7gBuq5Q3AiO0Ltk8CJ4Cr2z1+RES0R7bb21D6GWAH8DSNe/uHgduBs7YXNa33gu3Fku4CDtreXY3vBPbb3tti35uBzQD9/f1rR0ZGWmYYGxujr6+vrfxzoRf5jpx9adrr9i+Ec6/OYpgO1DkbJF+n6pxvYrY1yy7vXZgWptsrw8PDh20Ptprr5Bz/fODdwMdsPy7p96lO60xCLcZa3urY3kHjRoXBwUEPDQ213OHo6CiTzdVBL/LN5Jz9ljXj3Hmko6d5Zk2ds0HydarO+SZmO3XTUO/CtNCNXunkHP8Z4Iztx6vLe2ncEJyTtBSg+n6+af0VTdsvB57r4PgREdGGtovf9reBb0l6VzW0jsZpn33ApmpsE/BAtbwP2ChpgaSVwCrgULvHj4iI9nT6WOtjwJckvQ34K+Bf0bgx2SPpVuA0cCOA7WOS9tC4cRgHbrN9scPjR0TEDHVU/La/BrR68mDdJOtvB7Z3csyIiOhM3rkbEVGYFH9ERGFS/BERhUnxR0QUJsUfEVGYFH9ERGFS/BERhUnxR0QUJsUfEVGYFH9ERGFS/BERhUnxR0QUJsUfEVGYFH9ERGFS/BERhUnxR0QUJsUfEVGYFH9ERGFS/BERhUnxR0QUpqP/bD1aG9j6EABb1oxzS7UcEVEXHd/jlzRP0lclPVhdvkLSw5Kerb4vblp3m6QTko5LurbTY0dExMx141TP7cAzTZe3AgdsrwIOVJeRtBrYCFwJrAfuljSvC8ePiIgZ6Kj4JS0HPgjc0zS8AdhVLe8CbmgaH7F9wfZJ4ARwdSfHj4iImZPt9jeW9gK/Cfwo8HHb10l60faipnVesL1Y0l3AQdu7q/GdwH7be1vsdzOwGaC/v3/tyMhIy+OPjY3R19fXdv7ZcuTsSwD0L4Rzr/Y4zBuoc746Z4Pk61Sd803MtmbZ5b0L08J0e294ePiw7cFWc20/uSvpOuC87cOShqazSYuxlrc6tncAOwAGBwc9NNR696Ojo0w210u3ND25e+eR+j5/Xud8dc4GydepOuebmO3UTUO9C9NCN3qvk9/8e4DrJX0AeDtwmaTdwDlJS20/L2kpcL5a/wywomn75cBzHRw/IiLa0PY5ftvbbC+3PUDjSds/t30zsA/YVK22CXigWt4HbJS0QNJKYBVwqO3kERHRltl4rHUHsEfSrcBp4EYA28ck7QGeBsaB22xfnIXjR0TEG+hK8dseBUar5f8DrJtkve3A9m4cMyIi2pOPbIiIKEyKPyKiMCn+iIjCpPgjIgqT4o+IKEyKPyKiMCn+iIjCpPgjIgqT4o+IKEyKPyKiMCn+iIjCpPgjIgqT4o+IKEyKPyKiMCn+iIjCpPgjIgqT4o+IKEyKPyKiMCn+iIjCpPgjIgqT4o+IKEzbxS9phaRHJD0j6Zik26vxKyQ9LOnZ6vvipm22SToh6bika7vxA0RExMx0co9/HNhi++8C1wC3SVoNbAUO2F4FHKguU81tBK4E1gN3S5rXSfiIiJi5tovf9vO2n6yWXwaeAZYBG4Bd1Wq7gBuq5Q3AiO0Ltk8CJ4Cr2z1+RES0R7Y734k0ADwKXAWctr2oae4F24sl3QUctL27Gt8J7Le9t8X+NgObAfr7+9eOjIy0PO7Y2Bh9fX0d5++2I2dfAqB/IZx7tcdh3kCd89U5GyRfp+qcb2K2Ncsu712YFqbbe8PDw4dtD7aam99pCEl9wB8Cv277ryVNumqLsZa3OrZ3ADsABgcHPTQ01HKHo6OjTDbXS7dsfQiALWvGufNIx7/iWVPnfHXOBsnXqTrnm5jt1E1DvQvTQjd6r6NX9Uj6ERql/yXb91fD5yQtreaXAuer8TPAiqbNlwPPdXL8iIiYubZvctW4a78TeMb2Z5qm9gGbgDuq7w80jX9Z0meAdwKrgEPtHn86Bqp73hER8UOdPNZ6D/DLwBFJX6vG/h2Nwt8j6VbgNHAjgO1jkvYAT9N4RdBtti92cPyIiGhD28Vv+y9ofd4eYN0k22wHtrd7zIiI6FzeuRsRUZgUf0REYVL8ERGFSfFHRBQmxR8RUZgUf0REYVL8ERGFSfFHRBQmxR8RUZgUf0REYVL8ERGFSfFHRBQmxR8RUZgUf0REYVL8ERGFSfFHRBQmxR8RUZgUf0REYVL8ERGF6eQ/W4+IeMsb2PpQT4576o4Pztq+c48/IqIwKf6IiMLMefFLWi/puKQTkrbO9fEjIko3p8UvaR7wOeAXgdXAhyStnssMERGlm+t7/FcDJ2z/le3vAyPAhjnOEBFRNNmeu4NJ/xJYb/tXqsu/DPwD2786Yb3NwObq4ruA45Pscgnw3VmK2w3J1746Z4Pk61Sd89U5G0w/39+x/eOtJub65ZxqMfa6Wx7bO4AdU+5MesL2YDeCzYbka1+ds0HydarO+eqcDbqTb65P9ZwBVjRdXg48N8cZIiKKNtfF/7+AVZJWSnobsBHYN8cZIiKKNqenemyPS/pV4E+BecC9to91sMspTwf1WPK1r87ZIPk6Ved8dc4GXcg3p0/uRkRE7+WduxERhUnxR0QU5k1Z/HX72AdJKyQ9IukZScck3V6NXyHpYUnPVt8X9zjnPElflfRg3fJJWiRpr6RvVL/Hf1iXfJJ+o/p3PSrpPklv72U2SfdKOi/paNPYpHkkbauuK8clXdujfL9T/dt+XdIfSVpUp3xNcx+XZElL6pZP0seqDMck/XZH+Wy/qb5oPCn8TeAngLcBTwGre5xpKfDuavlHgb+k8ZEUvw1srca3Ar/V45z/Bvgy8GB1uTb5gF3Ar1TLbwMW1SEfsAw4CSysLu8BbullNuAXgHcDR5vGWuap/g6fAhYAK6vrzrwe5PunwPxq+bfqlq8aX0HjhSf/G1hSp3zAMPBnwILq8js6yfdmvMdfu499sP287Ser5ZeBZ2gUxgYahUb1/YaeBAQkLQc+CNzTNFyLfJIuo/HHvhPA9vdtv1iXfDRe/bZQ0nzgEhrvPelZNtuPAt+bMDxZng3AiO0Ltk8CJ2hch+Y0n+2v2B6vLh6k8R6e2uSr/C7wCf7/N5XWJd9HgTtsX6jWOd9Jvjdj8S8DvtV0+Uw1VguSBoCfBR4H+m0/D40bB+AdPYz2ezT+qP9v01hd8v0E8B3gv1Snou6RdGkd8tk+C/xH4DTwPPCS7a/UIdsEk+Wp4/XlI8D+arkW+SRdD5y1/dSEqVrkA34KeK+kxyX9T0k/V423le/NWPzT+tiHXpDUB/wh8Ou2/7rXeV4j6TrgvO3Dvc4yifk0Htp+3vbPAq/QOF3Rc9W58g00Hka/E7hU0s29TTUjtbq+SPoUMA586bWhFqvNaT5JlwCfAv59q+kWY734/c0HFgPXAP8W2CNJtJnvzVj8tfzYB0k/QqP0v2T7/mr4nKSl1fxS4Pxk28+y9wDXSzpF49TY+yTtrlG+M8AZ249Xl/fSuCGoQ773Aydtf8f2D4D7gZ+vSbZmk+WpzfVF0ibgOuAmVyeoqUe+n6Rxw/5UdR1ZDjwp6W/XJB9VjvvdcIjGI/cl7eZ7MxZ/7T72obrl3Qk8Y/szTVP7gE3V8ibggbnOBmB7m+3ltgdo/L7+3PbNNcr3beBbkt5VDa0DnqYe+U4D10i6pPp3XkfjOZw6ZGs2WZ59wEZJCyStBFYBh+Y6nKT1wCeB623/TdNUz/PZPmL7HbYHquvIGRov1vh2HfJV/hh4H4Ckn6LxAojvtp1vNp+dnsVnvT9A45Uz3wQ+VYM8/4jGw6uvA1+rvj4A/BhwAHi2+n5FDbIO8cNX9dQmH/AzwBPV7/CPaTysrUU+4D8A3wCOAv+VxisoepYNuI/G8w0/oFFSt75RHhqnMb5J4+PNf7FH+U7QOBf92vXjP9cp34T5U1Sv6qlLPhpFv7v6G3wSeF8n+fKRDRERhXkznuqJiIgOpPgjIgqT4o+IKEyKPyKiMCn+iIjCpPgjIgqT4o+IKMz/A2RW0Zptz3pFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of tweet lengths after cleaning. Much more normal :)\n",
    "\n",
    "tweets['text'].apply(len).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "statutory-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the trainer is expecting a 'label' (see the forward method in the docs)\n",
    "tweets['label'] = tweets['target']\n",
    "del tweets['target']\n",
    "\n",
    "tweet_dataset = Dataset.from_pandas(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a720bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "twelve-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_MODEL = 'distilbert-base-uncased'  # uncased will lowercase everything and remove accents\n",
    "\n",
    "# reminder uncased vs cased. We are using uncased to simplify and we don't think case will matter here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "furnished-specification",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "bert_tokenizer = DistilBertTokenizer.from_pretrained(BERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "intermediate-treasury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55cf0b3899654bafa4a4a66c062ace86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# simple function to batch tokenize utterances with truncation\n",
    "def preprocess_function(examples):\n",
    "    return bert_tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tweet_dataset = tweet_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "willing-antigua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e898db69ca1e45549e57ded1f6b57403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0cc2eb00354851b00efea9c0b681e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset has a built in train test split method\n",
    "tweet_dataset = tweet_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ab5c8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset(features: {'text': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None), 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}, num_rows: 6090),\n",
       " 'test': Dataset(features: {'text': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None), 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}, num_rows: 1523)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9061f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dataset.remove_column_('text')  # remove the text column because we don't need to keep it in memory anymore\n",
    "# this is not required but speeds things up a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "involved-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# DataCollatorWithPadding creates batch of data. It also dynamically pads text to the \n",
    "#  length of the longest element in the batch, making them all the same length. \n",
    "#  It's possible to pad your text in the tokenizer function with padding=True, dynamic padding is more efficient.\n",
    "data_collator = DataCollatorWithPadding(tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5c7c6ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'input_ids': [101,\n",
       "  15786,\n",
       "  9451,\n",
       "  1011,\n",
       "  2184,\n",
       "  4731,\n",
       "  11564,\n",
       "  2088,\n",
       "  4432,\n",
       "  14120,\n",
       "  24471,\n",
       "  2140,\n",
       "  102],\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fdd874f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] laos flooding - 10 villages underwater world vision responding url [SEP]'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.decode(tweet_dataset['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c77f5caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 0, 0, 0]]), 'input_ids': tensor([[  101, 15786,  9451,  1011,  2184,  4731, 11564,  2088,  4432, 14120,\n",
       "         24471,  2140,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [  101,  1996, 23512,  2466,  1997,  2108,  1037, 13446,  1011,  1996,\n",
       "         23512,  2466,  1997,  2108,  1037, 13446,  2009,  1005,  1055,  3326,\n",
       "          1998,  2006,  1037,  2329,  1012,  1012,  1012, 24471,  2140,   102,\n",
       "             0],\n",
       "        [  101,  2043,  2017,  2175,  2000,  1037,  4164,  1998,  2619, 11652,\n",
       "          1999,  2115,  4540,  1012,  1012,  1012,  2515,  2009,  2298,  2066,\n",
       "          1045, 10587,  6065,  2026,  4994, 15933,  2574,  1029,  1029,  1029,\n",
       "           102],\n",
       "        [  101,  2339,  2003,  2045,  2019, 10771,  2157,  2648,  2026,  2147,\n",
       "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [  101,  2027, 27788,  2098,  2009,  1999,  2000,  1017,  8974,  2169,\n",
       "          2005,  1016,  2111,  2021,  2069,  2006,  4070,  1997,  2205,  2116,\n",
       "          4634,  1011,  2125,  1011, 14708,  8664,   999,   102,     0,     0,\n",
       "             0]]), 'labels': tensor([1, 1, 1, 0, 0])}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator(tweet_dataset['train'][:5])\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ff1749e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a6509f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['attention_mask']  # 1's where we have tokens we are about and 0 where we don't want to calculate attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18847f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 15786,  9451,  1011,  2184,  4731, 11564,  2088,  4432, 14120,\n",
       "         24471,  2140,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [  101,  1996, 23512,  2466,  1997,  2108,  1037, 13446,  1011,  1996,\n",
       "         23512,  2466,  1997,  2108,  1037, 13446,  2009,  1005,  1055,  3326,\n",
       "          1998,  2006,  1037,  2329,  1012,  1012,  1012, 24471,  2140,   102,\n",
       "             0],\n",
       "        [  101,  2043,  2017,  2175,  2000,  1037,  4164,  1998,  2619, 11652,\n",
       "          1999,  2115,  4540,  1012,  1012,  1012,  2515,  2009,  2298,  2066,\n",
       "          1045, 10587,  6065,  2026,  4994, 15933,  2574,  1029,  1029,  1029,\n",
       "           102],\n",
       "        [  101,  2339,  2003,  2045,  2019, 10771,  2157,  2648,  2026,  2147,\n",
       "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [  101,  2027, 27788,  2098,  2009,  1999,  2000,  1017,  8974,  2169,\n",
       "          2005,  1016,  2111,  2021,  2069,  2006,  4070,  1997,  2205,  2116,\n",
       "          4634,  1011,  2125,  1011, 14708,  8664,   999,   102,     0,     0,\n",
       "             0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids']  # token ids are padded at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6120edf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] laos flooding - 10 villages underwater world vision responding url [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.decode(batch['input_ids'][0])  # see the pad tokens. 0 --> [PAD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84beb25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c4b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c961ba6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "smoking-vertical",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "\n",
    "sequence_classification_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    BERT_MODEL, num_labels=2,\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "sequence_classification_model.config.id2label = {0: 'NOT DISASTER', 1: 'DISASTER'}\n",
    "\n",
    "sequence_classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-canon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "instrumental-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-retrieval",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "stupid-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 3\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./clf/results',\n",
    "    logging_dir='./clf/logs',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size * 2,\n",
    "    logging_strategy='steps',\n",
    "    logging_first_step=True,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy='epoch',\n",
    "    eval_steps=1,\n",
    "    save_strategy='epoch'\n",
    ")\n",
    "\n",
    "# Define the trainer: \n",
    "\n",
    "trainer = Trainer(\n",
    "    model=sequence_classification_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tweet_dataset['train'],\n",
    "    eval_dataset=tweet_dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8cfec192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1523\n",
      "  Batch size = 64\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 02:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6840384006500244,\n",
       " 'eval_accuracy': 0.5673013788575181,\n",
       " 'eval_runtime': 135.9304,\n",
       " 'eval_samples_per_second': 11.204,\n",
       " 'eval_steps_per_second': 0.177}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get initial metrics\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "traditional-audit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinanozdemir/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6090\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 573\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [573/573 1:26:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.429883</td>\n",
       "      <td>0.826001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.416998</td>\n",
       "      <td>0.826658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.235200</td>\n",
       "      <td>0.494867</td>\n",
       "      <td>0.828628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1523\n",
      "  Batch size = 64\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./clf/results/checkpoint-191\n",
      "Configuration saved in ./clf/results/checkpoint-191/config.json\n",
      "Model weights saved in ./clf/results/checkpoint-191/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1523\n",
      "  Batch size = 64\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./clf/results/checkpoint-382\n",
      "Configuration saved in ./clf/results/checkpoint-382/config.json\n",
      "Model weights saved in ./clf/results/checkpoint-382/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1523\n",
      "  Batch size = 64\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./clf/results/checkpoint-573\n",
      "Configuration saved in ./clf/results/checkpoint-573/config.json\n",
      "Model weights saved in ./clf/results/checkpoint-573/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./clf/results/checkpoint-382 (score: 0.4169979691505432).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=573, training_loss=0.3158576113495319, metrics={'train_runtime': 5204.4113, 'train_samples_per_second': 3.51, 'train_steps_per_second': 0.11, 'total_flos': 193309778348856.0, 'train_loss': 0.3158576113495319, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "lesbian-smoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1523\n",
      "  Batch size = 64\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 02:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4169979691505432,\n",
       " 'eval_accuracy': 0.8266579120157583,\n",
       " 'eval_runtime': 143.2645,\n",
       " 'eval_samples_per_second': 10.631,\n",
       " 'eval_steps_per_second': 0.168,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get post-training metrics\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "signed-mitchell",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./clf/results\n",
      "Configuration saved in ./clf/results/config.json\n",
      "Model weights saved in ./clf/results/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()  # save our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nuclear-match",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# make a classification pipeline\n",
    "pipe = pipeline(\"text-classification\", './clf/results', tokenizer=BERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "advised-playing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'DISASTER', 'score': 0.9625178575515747}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('this is awful. Such a terrible earthquake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc8d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
